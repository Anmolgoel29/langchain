{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model \n",
    "from langchain_core.runnables import RunnableLambda, RunnableParallel, RunnableMap\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "from IPython.display import display, Markdown\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(model=\"deepseek/deepseek-chat-v3-0324:free\",model_provider=\"openai\") # initializing chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It looks like you're speaking **Punjabi**!  \n",
      "\n",
      "The phrase **\"tussi ki kr rhe ho\"** translates to **\"What are you doing?\"** in English.  \n",
      "\n",
      "If you'd like any help with translations, learning Punjabi, or anything else, feel free to ask! üòä\n"
     ]
    }
   ],
   "source": [
    "print(model.invoke([{\"role\":\"system\" , \"content\": \"what language do you think the user is speaking in?\"} , {\"role\": \"user\", \"content\": \"tussi ki kr rhe ho\"}]).content) # low level model prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Runnables\n",
    "Following I give examples of usage of various types of runnables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RunnableLambda: to wrap any python function into a runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used a runnable to print \"Hello world!\"\n"
     ]
    }
   ],
   "source": [
    "def pr(text : str) -> str:\n",
    "    print(f\"Used a runnable to print {text}\")\n",
    "\n",
    "runnable = RunnableLambda(pr)\n",
    "runnable.invoke(\"\\\"Hello world!\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RunnableParallel: chain various tasks to execute in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used a runnable to print Hello World! Testing 1 2 3 ....\n",
      "7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pr': None, 'word_count': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_count_runnable(text : str) -> str:\n",
    "    print(len(text.split()))\n",
    "\n",
    "parallelRunnable = RunnableParallel(\n",
    "    pr = pr , \n",
    "    word_count = word_count_runnable\n",
    ")\n",
    "\n",
    "parallelRunnable.invoke(\"Hello World! Testing 1 2 3 ....\")\n",
    "\n",
    "# Here both the funcitons were executed parallely and whatever they returned was retured as dict by the invoke call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RunnableMap: same as RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used a runnable to print whats up\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pr': None, 'word_count': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable = RunnableMap(\n",
    "    pr = pr,\n",
    "    word_count = word_count_runnable\n",
    ")\n",
    "\n",
    "runnable.invoke(\"whats up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Chaining various runnables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "def add_three(num : int) -> int:\n",
    "    return num + 3\n",
    "def add_two(num : int) -> int:\n",
    "    return num + 2\n",
    "def add_one(num : int) -> int:\n",
    "    return num + 1\n",
    "\n",
    "runnable_1 = RunnableLambda(add_one)\n",
    "runnable_2 = RunnableLambda(add_two)\n",
    "runnable_3 = RunnableLambda(add_three)\n",
    "\n",
    "chain = runnable_1 | runnable_2 | runnable_3\n",
    "\n",
    "print(chain.invoke(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streaming : \n",
    "- Streaming is critical in making applications based on LLMs feel responsive to end-users.\n",
    "- Basically here we print the tokens one by one as we get them instead of just printing then all together at the end to keep the user enagaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The phrase **\"tussi ki kr rhe ho\"** is in **Punjabi** (Gurmukhi script: **‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®ï‡©Ä ‡®ï‡®∞ ‡®π‡©á ‡®π‡©ã?**), which translates to **\"What are you doing?\"** in English.  \n",
      "\n",
      "### Breakdown:\n",
      "- **‡®§‡©Å‡®∏‡©Ä‡®Ç (tussƒ´ÃÉ)** = You (formal)  \n",
      "- **‡®ï‡©Ä (kƒ´)** = What  \n",
      "- **‡®ï‡®∞ ‡®π‡©á ‡®π‡©ã (kar rahe ho)** = Are doing  \n",
      "\n",
      "Let me know if you'd like any other details! "
     ]
    }
   ],
   "source": [
    "for i in model.stream([{\"role\":\"system\" , \"content\": \"what language do you think the user is speaking in? and then write the phrase in the native script of the language\"} , {\"role\": \"user\", \"content\": \"tussi ki kr rhe ho\"}]):\n",
    "    print(i.content,end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Messages:\n",
    "Here we can pass vraious types of mesasge to llm model to get better responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I'm sorry to hear you're feeling sad, but I'm here to help! Here are some fun and uplifting ideas to brighten your day:  \n",
       "\n",
       "1. **Dance Party** ‚Äì Put on your favorite upbeat songs and dance like nobody's watching!  \n",
       "2. **Watch a Funny Movie/Show** ‚Äì Laughter is the best medicine! Try classics like *The Office*, *Friends*, or *Monty Python*.  \n",
       "3. **Creative Outlet** ‚Äì Draw, paint, write a silly poem, or try DIY crafts (even if it‚Äôs messy!).  \n",
       "4. **Virtual Adventure** ‚Äì Take a free virtual tour of museums, zoos, or even the International Space Station!  \n",
       "5. **Bake Something Sweet** ‚Äì Cookies, brownies, or a simple mug cake can be delicious therapy.  \n",
       "6. **Play with Pets (or Watch Cute Animal Videos)** ‚Äì If you don‚Äôt have a pet, YouTube has endless adorable animal clips!  \n",
       "7. **Gratitude List** ‚Äì Write down 3 small things you‚Äôre grateful for‚Äîit can shift your mood.  \n",
       "8. **Random Act of Kindness** ‚Äì Compliment someone, send a nice text, or donate to a cause‚Äîit feels great!  \n",
       "\n",
       "Would you like something more specific‚Äîlike a game, a mindfulness exercise, or a feel-good playlist? I‚Äôm happy to tailor suggestions for you. üíõ"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "message = [\n",
    "    SystemMessage(\"You are a helpful ai chatbot whose task is to help the user in any way possible and be utmost polite with them\"),\n",
    "    HumanMessage(\"Hello how are you\"),\n",
    "    AIMessage(\"I am fine, how are you doing?\"),\n",
    "    HumanMessage(\"I am feeling sad today suggest something fun to me\")\n",
    "]\n",
    "\n",
    "display(Markdown(model.invoke(message).content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt Template:\n",
    "- Most of the times the prompt we give to the ai is based on a tmeplate with multiple vairables or specific structure.\n",
    "-  We can use this runnable to best manage messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6356/3261266335.py:10: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(prompt = prompt , llm = model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 10 key pointers on **equality**:  \n",
      "\n",
      "1. **Equal Rights** ‚Äì Every individual should have the same legal, social, and political rights, regardless of gender, race, religion, or background.  \n",
      "2. **Non-Discrimination** ‚Äì No one should face unfair treatment based on identity, disability, sexual orientation, or economic status.  \n",
      "3. **Equal Opportunities** ‚Äì Everyone should have access to education, jobs, healthcare, and resources to succeed.  \n",
      "4. **Gender Equality** ‚Äì Men and women should have equal rights, pay, and representation in all fields.  \n",
      "5. **Social Justice** ‚Äì Systems and policies should promote fairness and reduce inequalities in wealth and power.  \n",
      "6. **Inclusion** ‚Äì Society should embrace diversity and ensure marginalized groups have a voice.  \n",
      "7. **Economic Equality** ‚Äì Fair wages, wealth distribution, and opportunities should reduce income gaps.  \n",
      "8. **Education for All** ‚Äì Equal access to quality education helps break cycles of poverty and inequality.  \n",
      "9. **Legal Protection** ‚Äì Laws must uphold equality and punish discrimination, hate crimes, and bias.  \n",
      "10. **Cultural Shift** ‚Äì Changing mindsets through awareness and advocacy ensures long-term equality.  \n",
      "\n",
      "Would you like me to expand on any of these points?"
     ]
    }
   ],
   "source": [
    "systemTemplate = \"You are a helpful assitant chatbot to assist the user in any way possible\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\" , systemTemplate) , \n",
    "        (\"user\" , \"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = LLMChain(prompt = prompt , llm = model)\n",
    "\n",
    "for i in chain.stream(\"write 10 pointers on equality\"): # sop this shows that we can't easily stream the output in a chain\n",
    "    print(i['text'] , end=\"\",flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here are 10 key pointers on **equality**:  \n",
      "\n",
      "1. **Fundamental Right** ‚Äì Equality is a basic human right, ensuring that every individual is treated fairly without discrimination.  \n",
      "\n",
      "2. **Equal Opportunities** ‚Äì Everyone should have access to the same opportunities in education, employment, healthcare, and social participation.  \n",
      "\n",
      "3. **Non-Discrimination** ‚Äì No one should face prejudice based on race, gender, religion, caste, disability, sexual orientation, or economic status.  \n",
      "\n",
      "4. **Legal Protection** ‚Äì Laws and policies must safeguard equality and penalize discriminatory practices.  \n",
      "\n",
      "5. **Gender Equality** ‚Äì Equal rights and respect for all genders, including fair wages, representation, and freedom from stereotypes.  \n",
      "\n",
      "6. **Social Justice** ‚Äì Addressing systemic inequalities to ensure marginalized groups receive fair treatment and support.  \n",
      "\n",
      "7. **Economic Equality** ‚Äì Reducing wealth gaps through fair wages, taxation, and social welfare programs.  \n",
      "\n",
      "8. **Inclusive Representation** ‚Äì Diverse voices must be included in decision-making processes (politics, workplaces, media).  \n",
      "\n",
      "9. **Education & Awareness** ‚Äì Promoting equality through education to eliminate biases and foster empathy.  \n",
      "\n",
      "10. **Global Effort** ‚Äì Equality must be pursued internationally through cooperation, treaties, and humanitarian efforts.  \n",
      "\n",
      "Would you like me to elaborate on any of these points?"
     ]
    }
   ],
   "source": [
    "for i in model.stream(prompt.invoke(\"write 10 pointers on equality\")):\n",
    "    print(i.content, end=\"\",flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assitant chatbot to assist the user in any way possible', additional_kwargs={}, response_metadata={}), HumanMessage(content='to rbo', additional_kwargs={}, response_metadata={}), AIMessage(content='whatsup', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\" , systemTemplate) , \n",
    "        (\"user\" , \"{text}\"),\n",
    "        (\"ai\" , \"{aitext}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt.invoke({\"text\":\"to rbo\" , \"aitext\":\"whatsup\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
